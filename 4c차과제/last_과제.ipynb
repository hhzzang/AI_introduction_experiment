{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23edd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, npy_dir,tfms=None):\n",
    "        self.dir_path = npy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        # all npy path\n",
    "        self.npy_path = glob.glob(os.path.join(npy_dir, '*','*.npy')) \n",
    "        self.tfms = tfms\n",
    "    def __getitem__(self, index):\n",
    "        # load data\n",
    "        single_data_path = self.npy_path[index]\n",
    "        data = np.load(single_data_path, allow_pickle=True)\n",
    "        \n",
    "        image = Image.fromarray(data[0])\n",
    "        if self.tfms:\n",
    "            image = self.tfms(image)\n",
    "        else:\n",
    "            image = self.to_tensor(image)\n",
    "        label = data[1]\n",
    "       \n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "\n",
    "\n",
    "trtfm = transforms.Compose([\n",
    "                    \n",
    "                    transforms.RandomRotation(degrees=(-10, 10),fill=1),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.6647), (0.73155)),\n",
    "                    \n",
    "                    ])\n",
    "tttfm = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.6647), (0.73155))])\n",
    "\n",
    "# load dataset \n",
    "train_data = MyDataset(\"./Font_npy_90_train\",trtfm)\n",
    "valid_data = MyDataset(\"./Font_npy_90_val\",tttfm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb4b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        out = model(image)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        acc += (pred==label).sum()\n",
    "        epoch_loss += loss.item()\n",
    "        total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "\n",
    "def valid(model, data_loader, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = model(image)\n",
    "            loss = criterion(out, label)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            acc += (pred==label).sum()\n",
    "            epoch_loss += loss.item()\n",
    "            total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdfbf181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42feaa8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:27<35:59, 27.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/80], Train Loss:66.6886, Train Acc:0.78\n",
      "6.775733940303326 tensor(0.9015, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 2/80 [00:54<35:31, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/80], Train Loss:27.7925, Train Acc:0.90\n",
      "5.914015024900436 tensor(0.9122, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 3/80 [01:22<35:04, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/80], Train Loss:21.7831, Train Acc:0.92\n",
      "4.535429164767265 tensor(0.9278, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 4/80 [01:49<34:43, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/80], Train Loss:17.9348, Train Acc:0.93\n",
      "4.025075811892748 tensor(0.9412, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 5/80 [02:17<34:20, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/80], Train Loss:15.6359, Train Acc:0.94\n",
      "4.075694173574448 tensor(0.9417, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 6/80 [02:44<33:55, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/80], Train Loss:14.4087, Train Acc:0.94\n",
      "3.538475861772895 tensor(0.9437, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 7/80 [03:11<33:21, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/80], Train Loss:13.3652, Train Acc:0.95\n",
      "3.167108938097954 tensor(0.9483, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 8/80 [03:39<32:51, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/80], Train Loss:11.7559, Train Acc:0.95\n",
      "3.0668698586523533 tensor(0.9504, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 9/80 [04:06<32:25, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/80], Train Loss:11.1128, Train Acc:0.96\n",
      "3.151340251788497 tensor(0.9532, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 10/80 [04:34<31:58, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/80], Train Loss:10.2594, Train Acc:0.96\n",
      "3.0025892946869135 tensor(0.9527, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 11/80 [05:01<31:31, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/80], Train Loss:10.0245, Train Acc:0.96\n",
      "3.065097436308861 tensor(0.9533, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 12/80 [05:28<31:04, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/80], Train Loss:9.3364, Train Acc:0.96\n",
      "3.068132412619889 tensor(0.9526, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 13/80 [05:56<30:35, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/80], Train Loss:8.8444, Train Acc:0.96\n",
      "2.6878916416317225 tensor(0.9569, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 14/80 [06:23<30:09, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/80], Train Loss:8.7480, Train Acc:0.96\n",
      "3.010805381461978 tensor(0.9562, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 15/80 [06:51<29:44, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/80], Train Loss:8.2373, Train Acc:0.97\n",
      "3.016680721193552 tensor(0.9509, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 16/80 [07:18<29:18, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/80], Train Loss:7.8636, Train Acc:0.97\n",
      "2.8451447188854218 tensor(0.9562, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 17/80 [07:46<28:50, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/80], Train Loss:7.7864, Train Acc:0.97\n",
      "2.6576433572918177 tensor(0.9564, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 18/80 [08:13<28:21, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18/80], Train Loss:7.5042, Train Acc:0.97\n",
      "3.112610657699406 tensor(0.9550, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 19/80 [08:41<27:54, 27.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/80], Train Loss:7.6907, Train Acc:0.97\n",
      "2.6909466749057174 tensor(0.9592, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 20/80 [09:08<27:27, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/80], Train Loss:7.0685, Train Acc:0.97\n",
      "2.5237384103238583 tensor(0.9588, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 21/80 [09:36<27:12, 27.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/80], Train Loss:6.7958, Train Acc:0.97\n",
      "2.6694387942552567 tensor(0.9568, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 22/80 [10:04<26:46, 27.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/80], Train Loss:6.7399, Train Acc:0.97\n",
      "2.59392034355551 tensor(0.9581, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 23/80 [10:32<26:17, 27.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/80], Train Loss:6.8996, Train Acc:0.97\n",
      "2.6499884109944105 tensor(0.9597, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 24/80 [10:59<25:48, 27.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/80], Train Loss:6.4145, Train Acc:0.97\n",
      "2.436101868748665 tensor(0.9603, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 25/80 [11:27<25:24, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/80], Train Loss:6.3137, Train Acc:0.97\n",
      "2.3834084598347545 tensor(0.9606, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 26/80 [11:55<24:57, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/80], Train Loss:6.0061, Train Acc:0.97\n",
      "2.6512882113456726 tensor(0.9595, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 27/80 [12:22<24:18, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[27/80], Train Loss:6.0931, Train Acc:0.97\n",
      "2.415182551369071 tensor(0.9614, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 28/80 [12:49<23:43, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/80], Train Loss:5.9742, Train Acc:0.97\n",
      "2.637335111387074 tensor(0.9595, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 29/80 [13:16<23:11, 27.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29/80], Train Loss:5.9900, Train Acc:0.97\n",
      "2.4753705067560077 tensor(0.9599, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 30/80 [13:44<22:48, 27.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/80], Train Loss:5.9385, Train Acc:0.98\n",
      "2.5792654175311327 tensor(0.9597, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 31/80 [14:11<22:21, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/80], Train Loss:5.9181, Train Acc:0.98\n",
      "2.472134428098798 tensor(0.9597, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 32/80 [14:38<21:54, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/80], Train Loss:6.0026, Train Acc:0.97\n",
      "2.553220615722239 tensor(0.9599, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 33/80 [15:06<21:27, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/80], Train Loss:5.7863, Train Acc:0.97\n",
      "2.53395330067724 tensor(0.9567, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 34/80 [15:33<21:02, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/80], Train Loss:5.4898, Train Acc:0.98\n",
      "2.579967537894845 tensor(0.9600, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 35/80 [16:01<20:36, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/80], Train Loss:5.4384, Train Acc:0.98\n",
      "2.68306224886328 tensor(0.9601, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 36/80 [16:28<20:09, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/80], Train Loss:5.7305, Train Acc:0.98\n",
      "2.53456794610247 tensor(0.9600, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 37/80 [16:56<19:47, 27.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/80], Train Loss:5.6677, Train Acc:0.98\n",
      "2.440634203143418 tensor(0.9600, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 38/80 [17:24<19:21, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/80], Train Loss:5.1000, Train Acc:0.98\n",
      "2.4641570849344134 tensor(0.9601, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 39/80 [17:52<18:53, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/80], Train Loss:5.0760, Train Acc:0.98\n",
      "2.4709925381466746 tensor(0.9600, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 40/80 [18:19<18:25, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/80], Train Loss:5.2421, Train Acc:0.98\n",
      "2.606430470943451 tensor(0.9621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 41/80 [18:47<17:56, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[41/80], Train Loss:5.0114, Train Acc:0.98\n",
      "2.512842277996242 tensor(0.9605, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 42/80 [19:14<17:27, 27.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[42/80], Train Loss:4.9731, Train Acc:0.98\n",
      "2.4414936343673617 tensor(0.9629, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 43/80 [19:42<16:59, 27.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43/80], Train Loss:5.0170, Train Acc:0.98\n",
      "2.414408848620951 tensor(0.9614, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 44/80 [20:09<16:30, 27.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[44/80], Train Loss:4.9336, Train Acc:0.98\n",
      "2.5860792538151145 tensor(0.9618, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 45/80 [20:37<16:03, 27.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[45/80], Train Loss:4.9157, Train Acc:0.98\n",
      "2.4633237002417445 tensor(0.9621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 46/80 [21:04<15:36, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46/80], Train Loss:4.8267, Train Acc:0.98\n",
      "2.4414752004668117 tensor(0.9612, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 47/80 [21:32<15:11, 27.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[47/80], Train Loss:4.8130, Train Acc:0.98\n",
      "2.5012519443407655 tensor(0.9613, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 48/80 [22:00<14:44, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[48/80], Train Loss:4.7997, Train Acc:0.98\n",
      "2.65440391888842 tensor(0.9596, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 49/80 [22:27<14:17, 27.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/80], Train Loss:4.8331, Train Acc:0.98\n",
      "2.447299857158214 tensor(0.9619, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 50/80 [22:55<13:48, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[50/80], Train Loss:4.9957, Train Acc:0.98\n",
      "2.4149060738272965 tensor(0.9631, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 51/80 [23:23<13:21, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[51/80], Train Loss:4.7079, Train Acc:0.98\n",
      "2.3145126793533564 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 52/80 [23:50<12:53, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[52/80], Train Loss:4.7358, Train Acc:0.98\n",
      "2.52470616158098 tensor(0.9629, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 53/80 [24:18<12:24, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[53/80], Train Loss:4.8606, Train Acc:0.98\n",
      "2.521777327405289 tensor(0.9638, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 54/80 [24:45<11:54, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[54/80], Train Loss:4.6623, Train Acc:0.98\n",
      "2.429478914476931 tensor(0.9604, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 55/80 [25:12<11:23, 27.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[55/80], Train Loss:4.5570, Train Acc:0.98\n",
      "2.489248109050095 tensor(0.9619, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 56/80 [25:39<10:54, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[56/80], Train Loss:4.5363, Train Acc:0.98\n",
      "2.439066652674228 tensor(0.9626, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 57/80 [26:07<10:28, 27.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[57/80], Train Loss:4.5172, Train Acc:0.98\n",
      "2.54014905821532 tensor(0.9637, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 58/80 [26:34<10:02, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[58/80], Train Loss:4.2788, Train Acc:0.98\n",
      "2.4207381405867636 tensor(0.9605, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 59/80 [27:02<09:35, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[59/80], Train Loss:4.2709, Train Acc:0.98\n",
      "2.524712779559195 tensor(0.9586, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 60/80 [27:29<09:08, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[60/80], Train Loss:4.3731, Train Acc:0.98\n",
      "2.721957726404071 tensor(0.9599, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 61/80 [27:56<08:40, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[61/80], Train Loss:4.3207, Train Acc:0.98\n",
      "2.4597589196637273 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 62/80 [28:24<08:13, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[62/80], Train Loss:4.4650, Train Acc:0.98\n",
      "2.6364170033484697 tensor(0.9600, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 63/80 [28:51<07:46, 27.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[63/80], Train Loss:4.2677, Train Acc:0.98\n",
      "2.4138028640300035 tensor(0.9635, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 64/80 [29:19<07:19, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[64/80], Train Loss:4.3052, Train Acc:0.98\n",
      "2.4557693218812346 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 65/80 [29:46<06:51, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[65/80], Train Loss:4.2472, Train Acc:0.98\n",
      "2.3946693409234285 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 66/80 [30:14<06:24, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[66/80], Train Loss:4.2632, Train Acc:0.98\n",
      "2.520754737779498 tensor(0.9596, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 67/80 [30:41<05:57, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[67/80], Train Loss:4.0667, Train Acc:0.98\n",
      "2.636666923761368 tensor(0.9626, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 68/80 [31:08<05:28, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[68/80], Train Loss:4.1972, Train Acc:0.98\n",
      "2.426155806519091 tensor(0.9618, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 69/80 [31:35<04:59, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[69/80], Train Loss:4.2676, Train Acc:0.98\n",
      "2.3876711381599307 tensor(0.9631, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 70/80 [32:03<04:32, 27.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[70/80], Train Loss:4.2003, Train Acc:0.98\n",
      "2.4547106428071856 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 71/80 [32:30<04:05, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[71/80], Train Loss:4.1028, Train Acc:0.98\n",
      "2.4653156981803477 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 72/80 [32:58<03:39, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[72/80], Train Loss:4.0404, Train Acc:0.98\n",
      "2.397228868678212 tensor(0.9612, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 73/80 [33:25<03:11, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[73/80], Train Loss:4.1167, Train Acc:0.98\n",
      "2.426914131268859 tensor(0.9610, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 74/80 [33:53<02:44, 27.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[74/80], Train Loss:3.9732, Train Acc:0.98\n",
      "2.4843044336885214 tensor(0.9615, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 75/80 [34:20<02:17, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[75/80], Train Loss:3.9165, Train Acc:0.98\n",
      "2.4339377514552325 tensor(0.9633, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 76/80 [34:48<01:50, 27.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[76/80], Train Loss:4.0217, Train Acc:0.98\n",
      "2.5747898146510124 tensor(0.9609, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 77/80 [35:15<01:22, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[77/80], Train Loss:3.9359, Train Acc:0.98\n",
      "2.412325316108763 tensor(0.9614, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 78/80 [35:43<00:55, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[78/80], Train Loss:3.9260, Train Acc:0.98\n",
      "2.512137023732066 tensor(0.9603, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 79/80 [36:11<00:27, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[79/80], Train Loss:3.9978, Train Acc:0.98\n",
      "2.4624666403979063 tensor(0.9617, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [36:38<00:00, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[80/80], Train Loss:3.9077, Train Acc:0.98\n",
      "2.5227384008467197 tensor(0.9603, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2198.8919184207916"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, tqdm\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "\n",
    "model4 = MyNet(None, [1,1],52)\n",
    "model4.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.002)\n",
    "\n",
    "num_epochs = 80\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model4, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = valid(model4,valid_loader, criterion)\n",
    "    trl.append(train_loss)\n",
    "    tra.append(train_acc)\n",
    "    vall.append(valid_loss)\n",
    "    vala.append(valid_acc)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         best_epoch = epoch\n",
    "#         torch.save(model.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    print(valid_loss, valid_acc)\n",
    "#     if valid_acc > 0.9620:\n",
    "#         torch.save(model4.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "end = time.time()\n",
    "end-start\n",
    "# 구글 vs 내컴 : 280 -> 195\n",
    "# 경량화 모델 : 93.5 valid\n",
    "# 16으로 줄였을때 : 93 valid\n",
    "# 32으로 줄였을때 : 95.38 valid\n",
    "# 32에서 128block 하나 추가했을 때 : 0.9590\n",
    "# 32에서 128block,256block 두개 추가했을 때 : 0.9590\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.3) : 도달속도epoch 0.9368, 최고 0.9606\n",
    "# 32에서 128block 하나 추가했을 때 + dropout + regularizer  : 96.04\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.2) : 도달속도 epcoh5 0.9362 최고 \n",
    "\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout : 0.9606 모델 0.001 vs 0.005 vs 0.002 vs 0.0005 -> 0.002 이 더 빠름\n",
    "# resnet 1,1은 너무 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b88464",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:30<20:06, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/40], Train Loss:55.4048, Train Acc:0.73\n",
      "5.936474710702896 tensor(0.8836, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [00:59<18:37, 29.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/40], Train Loss:18.2363, Train Acc:0.91\n",
      "3.7610999196767807 tensor(0.9191, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [01:27<17:46, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/40], Train Loss:13.2529, Train Acc:0.93\n",
      "3.6229200959205627 tensor(0.9177, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [01:55<17:12, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/40], Train Loss:10.8556, Train Acc:0.94\n",
      "2.8231596648693085 tensor(0.9371, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [02:24<16:41, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/40], Train Loss:9.0387, Train Acc:0.95\n",
      "2.481726512312889 tensor(0.9399, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [02:52<16:09, 28.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/40], Train Loss:7.9835, Train Acc:0.95\n",
      "2.434001252055168 tensor(0.9412, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [03:21<15:40, 28.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/40], Train Loss:7.0716, Train Acc:0.96\n",
      "2.2444550171494484 tensor(0.9441, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [03:49<15:13, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/40], Train Loss:6.3689, Train Acc:0.96\n",
      "2.552134968340397 tensor(0.9381, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [04:37<17:46, 34.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/40], Train Loss:5.8655, Train Acc:0.97\n",
      "2.354900024831295 tensor(0.9462, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [05:18<18:15, 36.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/40], Train Loss:5.4107, Train Acc:0.97\n",
      "2.424376219511032 tensor(0.9476, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [05:46<16:22, 33.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/40], Train Loss:5.5517, Train Acc:0.97\n",
      "2.313086673617363 tensor(0.9479, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [06:14<14:58, 32.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/40], Train Loss:5.1067, Train Acc:0.97\n",
      "2.29758470505476 tensor(0.9510, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [06:42<13:51, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/40], Train Loss:4.4773, Train Acc:0.97\n",
      "2.150482013821602 tensor(0.9509, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [07:09<12:58, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/40], Train Loss:4.5817, Train Acc:0.97\n",
      "2.2738398611545563 tensor(0.9481, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [07:37<12:13, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/40], Train Loss:4.2936, Train Acc:0.97\n",
      "2.1885273456573486 tensor(0.9501, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [08:06<11:35, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/40], Train Loss:4.2150, Train Acc:0.97\n",
      "2.114317908883095 tensor(0.9524, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [08:34<11:02, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/40], Train Loss:4.0557, Train Acc:0.98\n",
      "2.289883889257908 tensor(0.9527, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [09:03<10:33, 28.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18/40], Train Loss:3.8644, Train Acc:0.98\n",
      "2.0337409377098083 tensor(0.9537, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [09:31<10:02, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/40], Train Loss:3.8011, Train Acc:0.98\n",
      "2.0049886628985405 tensor(0.9554, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [10:00<09:33, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/40], Train Loss:3.4628, Train Acc:0.98\n",
      "1.878500759601593 tensor(0.9540, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [10:28<09:03, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/40], Train Loss:3.6381, Train Acc:0.98\n",
      "1.9449028261005878 tensor(0.9569, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [10:57<08:33, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/40], Train Loss:3.3903, Train Acc:0.98\n",
      "1.978263322263956 tensor(0.9535, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [11:25<08:04, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/40], Train Loss:3.5426, Train Acc:0.98\n",
      "1.827479787170887 tensor(0.9562, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [11:53<07:35, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/40], Train Loss:3.2192, Train Acc:0.98\n",
      "2.0449125319719315 tensor(0.9565, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [12:22<07:07, 28.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/40], Train Loss:3.3143, Train Acc:0.98\n",
      "2.0266601517796516 tensor(0.9574, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [12:51<06:39, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/40], Train Loss:3.1893, Train Acc:0.98\n",
      "1.9291824288666248 tensor(0.9582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [13:19<06:10, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[27/40], Train Loss:3.0119, Train Acc:0.98\n",
      "1.9239913746714592 tensor(0.9556, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [13:47<05:41, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/40], Train Loss:3.0370, Train Acc:0.98\n",
      "1.8645441308617592 tensor(0.9573, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [14:16<05:13, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29/40], Train Loss:3.0878, Train Acc:0.98\n",
      "1.930979110300541 tensor(0.9571, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [14:44<04:44, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/40], Train Loss:3.0351, Train Acc:0.98\n",
      "2.0561088509857655 tensor(0.9581, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [15:13<04:15, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/40], Train Loss:2.8789, Train Acc:0.98\n",
      "1.8958607986569405 tensor(0.9556, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [15:41<03:47, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/40], Train Loss:2.8437, Train Acc:0.98\n",
      "2.0532113537192345 tensor(0.9585, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [16:09<03:18, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/40], Train Loss:2.9019, Train Acc:0.98\n",
      "1.9212289042770863 tensor(0.9582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [16:38<02:50, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/40], Train Loss:2.8437, Train Acc:0.98\n",
      "1.960752110928297 tensor(0.9582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [17:06<02:22, 28.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/40], Train Loss:2.7414, Train Acc:0.98\n",
      "1.8991326726973057 tensor(0.9573, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [17:35<01:53, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/40], Train Loss:2.6934, Train Acc:0.98\n",
      "1.9857887625694275 tensor(0.9550, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [18:03<01:25, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/40], Train Loss:2.7596, Train Acc:0.98\n",
      "1.963427945971489 tensor(0.9608, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [18:32<00:56, 28.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/40], Train Loss:2.7503, Train Acc:0.98\n",
      "1.7850428745150566 tensor(0.9608, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [19:00<00:28, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/40], Train Loss:2.6589, Train Acc:0.98\n",
      "1.889589834958315 tensor(0.9594, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [19:29<00:00, 29.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/40], Train Loss:2.5786, Train Acc:0.98\n",
      "1.7541182190179825 tensor(0.9579, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1169.1543028354645"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, tqdm\n",
    "batch_size = 768\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "\n",
    "model4 = MyNet(None, [1,1],52)\n",
    "model4.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.002)\n",
    "\n",
    "num_epochs = 40\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model4, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = valid(model4,valid_loader, criterion)\n",
    "#     trl.append(train_loss)\n",
    "#     tra.append(train_acc)\n",
    "#     vall.append(valid_loss)\n",
    "#     vala.append(valid_acc)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         best_epoch = epoch\n",
    "#         torch.save(model.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    print(valid_loss, valid_acc)\n",
    "end = time.time()\n",
    "end-start\n",
    "# 구글 vs 내컴 : 280 -> 195\n",
    "# 경량화 모델 : 93.5 valid\n",
    "# 16으로 줄였을때 : 93 valid\n",
    "# 32으로 줄였을때 : 95.38 valid\n",
    "# 32에서 128block 하나 추가했을 때 : 0.9590\n",
    "# 32에서 128block,256block 두개 추가했을 때 : 0.9590\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.3) : 도달속도epoch 0.9368, 최고 0.9606\n",
    "# 32에서 128block 하나 추가했을 때 + dropout + regularizer  : 96.04\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.2) : 도달속도 epcoh5 0.9362 최고 \n",
    "\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout : 0.9606 모델 0.001 vs 0.005 vs 0.002 vs 0.0005 -> 0.002 이 더 빠름\n",
    "# resnet 1,1은 너무 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ce9d40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:36<23:27, 36.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/40], Train Loss:46.7142, Train Acc:0.70\n",
      "5.408009886741638 tensor(0.8505, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [01:04<20:06, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/40], Train Loss:15.3900, Train Acc:0.90\n",
      "2.9848126471042633 tensor(0.9083, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [01:33<18:43, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/40], Train Loss:11.0001, Train Acc:0.92\n",
      "2.4206464141607285 tensor(0.9201, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [02:02<17:48, 29.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/40], Train Loss:9.0967, Train Acc:0.93\n",
      "2.1884885728359222 tensor(0.9318, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [02:30<17:06, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/40], Train Loss:7.7175, Train Acc:0.94\n",
      "1.9999942034482956 tensor(0.9362, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [02:59<16:31, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/40], Train Loss:6.7131, Train Acc:0.95\n",
      "1.8310119807720184 tensor(0.9412, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [03:28<15:58, 29.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/40], Train Loss:5.9140, Train Acc:0.95\n",
      "1.9045404940843582 tensor(0.9428, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [03:57<15:28, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/40], Train Loss:5.4181, Train Acc:0.96\n",
      "1.688267719000578 tensor(0.9432, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [04:26<14:58, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/40], Train Loss:4.8718, Train Acc:0.96\n",
      "1.7264378890395164 tensor(0.9435, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [04:54<14:25, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/40], Train Loss:4.8267, Train Acc:0.96\n",
      "1.6591468192636967 tensor(0.9440, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [05:23<13:55, 28.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/40], Train Loss:4.5899, Train Acc:0.97\n",
      "1.4126926735043526 tensor(0.9524, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [05:52<13:27, 28.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/40], Train Loss:4.1203, Train Acc:0.97\n",
      "1.5151922702789307 tensor(0.9490, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [06:21<12:59, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/40], Train Loss:4.1221, Train Acc:0.97\n",
      "1.4681867808103561 tensor(0.9521, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [06:50<12:30, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/40], Train Loss:3.8630, Train Acc:0.97\n",
      "1.5542484447360039 tensor(0.9505, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [07:19<12:03, 28.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/40], Train Loss:3.8659, Train Acc:0.97\n",
      "1.4832464531064034 tensor(0.9524, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [07:48<11:34, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/40], Train Loss:3.5904, Train Acc:0.97\n",
      "1.5296095833182335 tensor(0.9523, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [08:17<11:05, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/40], Train Loss:3.5197, Train Acc:0.97\n",
      "1.4264772534370422 tensor(0.9540, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [08:46<10:37, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18/40], Train Loss:3.3071, Train Acc:0.97\n",
      "1.406837061047554 tensor(0.9538, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [09:15<10:07, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/40], Train Loss:3.2506, Train Acc:0.97\n",
      "1.486531913280487 tensor(0.9526, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [09:44<09:38, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/40], Train Loss:3.0871, Train Acc:0.97\n",
      "1.4064833298325539 tensor(0.9550, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [10:13<09:10, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/40], Train Loss:2.9395, Train Acc:0.98\n",
      "1.3672774955630302 tensor(0.9532, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [10:42<08:41, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/40], Train Loss:2.7845, Train Acc:0.98\n",
      "1.4034896567463875 tensor(0.9505, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [11:10<08:11, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/40], Train Loss:2.9471, Train Acc:0.98\n",
      "1.4552526846528053 tensor(0.9547, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [11:39<07:40, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/40], Train Loss:2.8351, Train Acc:0.98\n",
      "1.5800805762410164 tensor(0.9483, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [12:08<07:11, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/40], Train Loss:2.7788, Train Acc:0.98\n",
      "1.4478778392076492 tensor(0.9568, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [12:36<06:41, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/40], Train Loss:2.9054, Train Acc:0.98\n",
      "1.4564736112952232 tensor(0.9560, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [13:05<06:13, 28.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[27/40], Train Loss:2.8056, Train Acc:0.98\n",
      "1.401016280055046 tensor(0.9560, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [13:34<05:44, 28.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/40], Train Loss:2.6640, Train Acc:0.98\n",
      "1.3678046390414238 tensor(0.9585, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [14:02<05:16, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29/40], Train Loss:2.6388, Train Acc:0.98\n",
      "1.5278807580471039 tensor(0.9528, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [14:32<04:48, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/40], Train Loss:2.6292, Train Acc:0.98\n",
      "1.4136394560337067 tensor(0.9564, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [15:01<04:20, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/40], Train Loss:2.5328, Train Acc:0.98\n",
      "1.3091213628649712 tensor(0.9579, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [15:30<03:51, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/40], Train Loss:2.3565, Train Acc:0.98\n",
      "1.494510568678379 tensor(0.9574, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [15:59<03:22, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/40], Train Loss:2.3401, Train Acc:0.98\n",
      "1.3945046812295914 tensor(0.9587, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [16:27<02:53, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/40], Train Loss:2.4456, Train Acc:0.98\n",
      "1.2996799945831299 tensor(0.9596, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [16:56<02:24, 28.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/40], Train Loss:2.3034, Train Acc:0.98\n",
      "1.3436139300465584 tensor(0.9582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [17:25<01:55, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/40], Train Loss:2.4162, Train Acc:0.98\n",
      "1.3798124939203262 tensor(0.9582, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [17:53<01:26, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/40], Train Loss:2.3241, Train Acc:0.98\n",
      "1.4057519808411598 tensor(0.9572, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [18:22<00:57, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/40], Train Loss:2.2766, Train Acc:0.98\n",
      "1.3401993587613106 tensor(0.9592, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [18:51<00:28, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/40], Train Loss:2.2475, Train Acc:0.98\n",
      "1.3641681224107742 tensor(0.9581, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [19:20<00:00, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/40], Train Loss:2.1357, Train Acc:0.98\n",
      "1.4198737442493439 tensor(0.9588, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1160.7241089344025"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, tqdm\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "\n",
    "model4 = MyNet(None, [1,1],52)\n",
    "model4.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.002)\n",
    "\n",
    "num_epochs = 40\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model4, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = valid(model4,valid_loader, criterion)\n",
    "#     trl.append(train_loss)\n",
    "#     tra.append(train_acc)\n",
    "#     vall.append(valid_loss)\n",
    "#     vala.append(valid_acc)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         best_epoch = epoch\n",
    "#         torch.save(model.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    print(valid_loss, valid_acc)\n",
    "end = time.time()\n",
    "end-start\n",
    "# 구글 vs 내컴 : 280 -> 195\n",
    "# 경량화 모델 : 93.5 valid\n",
    "# 16으로 줄였을때 : 93 valid\n",
    "# 32으로 줄였을때 : 95.38 valid\n",
    "# 32에서 128block 하나 추가했을 때 : 0.9590\n",
    "# 32에서 128block,256block 두개 추가했을 때 : 0.9590\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.3) : 도달속도epoch 0.9368, 최고 0.9606\n",
    "# 32에서 128block 하나 추가했을 때 + dropout + regularizer  : 96.04\n",
    "# 32에서 128block 하나 추가했을 때 + dropout(0.2) : 도달속도 epcoh5 0.9362 최고 \n",
    "\n",
    "\n",
    "# 32에서 128block 하나 추가했을 때 + dropout : 0.9606 모델 0.001 vs 0.005 vs 0.002 vs 0.0005 -> 0.002 이 더 빠름\n",
    "# resnet 1,1은 너무 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc1fd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a441a975",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4484/2848892561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mvala\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#     scheduler.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4484/3088433422.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4484/3994827780.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msingle_data_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnpy_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time, tqdm\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "\n",
    "model = MyNet(Block, [1,1],52)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "#     scheduler.step()\n",
    "    valid_loss, valid_acc = valid(model,valid_loader, criterion)\n",
    "#     trl.append(train_loss)\n",
    "#     tra.append(train_acc)\n",
    "#     vall.append(valid_loss)\n",
    "#     vala.append(valid_acc)\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         best_epoch = epoch\n",
    "#         torch.save(model.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    print(valid_loss, valid_acc)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46b596c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model1 = copy.deepcopy(model)\n",
    "model2 = copy.deepcopy(model)\n",
    "model3 = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99770265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:27<01:49, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/5], Train Loss:9.7468, Train Acc:0.93\n",
      "2.358025684952736 tensor(0.9268, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:54<01:22, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/5], Train Loss:9.8106, Train Acc:0.93\n",
      "2.3581302762031555 tensor(0.9269, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [01:22<00:54, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/5], Train Loss:9.6612, Train Acc:0.93\n",
      "2.3587816655635834 tensor(0.9267, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [01:49<00:27, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/5], Train Loss:9.6990, Train Acc:0.93\n",
      "2.3575128614902496 tensor(0.9269, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:56<00:29, 29.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33356/79924870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mvala\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33356/1999072226.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33356/3994827780.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msingle_data_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnpy_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time, tqdm\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "num_epochs = 5\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model3, train_loader, optimizer2, criterion)\n",
    "    valid_loss, valid_acc = valid(model3,valid_loader, criterion)\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    print(valid_loss, valid_acc)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride):\n",
    "        super(Block, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self.conv1 =  nn.Conv2d(inplanes, planes, kernel_size=3,stride=stride,bias=False,padding=1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=stride,bias=False,padding=1)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[1], stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks,stride):\n",
    "        norm_layer = self._norm_layer\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride))\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, stride))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccf37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride):\n",
    "        super(Block, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self.conv1 =  nn.Conv2d(inplanes, planes, kernel_size=3,stride=stride,bias=False,padding=1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[1], stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks,stride):\n",
    "        norm_layer = self._norm_layer\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride))\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, stride))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion,sche):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        out = model(image)\n",
    "        if i ==0:\n",
    "            print(image.shape)\n",
    "            print(label.shape)\n",
    "            print(out.shape)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        acc += (pred==label).sum()\n",
    "        epoch_loss += loss.item()\n",
    "        total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "\n",
    "def valid(model, data_loader, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = model(image)\n",
    "            loss = criterion(out, label)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            acc += (pred==label).sum()\n",
    "            epoch_loss += loss.item()\n",
    "            total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(18432, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885523f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(18432, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, npy_dir,tfms=None):\n",
    "        self.dir_path = npy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        # all npy path\n",
    "        self.npy_path = glob.glob(os.path.join(npy_dir, '*','*.npy')) \n",
    "        self.tfms = tfms\n",
    "    def __getitem__(self, index):\n",
    "        # load data\n",
    "        single_data_path = self.npy_path[index]\n",
    "        data = np.load(single_data_path, allow_pickle=True)\n",
    "        \n",
    "        image = data[0]\n",
    "        if self.tfms:\n",
    "            image = self.tfms(image)\n",
    "        else:\n",
    "            image = self.to_tensor(image)\n",
    "        label = data[1]\n",
    "       \n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        out = model(image)\n",
    "        if i ==0:\n",
    "            print(image.shape)\n",
    "            print(label.shape)\n",
    "            print(out.shape)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        acc += (pred==label).sum()\n",
    "        epoch_loss += loss.item()\n",
    "        total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "\n",
    "def valid(model, data_loader, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = model(image)\n",
    "            loss = criterion(out, label)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            acc += (pred==label).sum()\n",
    "            epoch_loss += loss.item()\n",
    "            total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "tfm = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5), (0.497))])\n",
    "# load dataset \n",
    "train_data = MyDataset(\"./Font_npy_90_train\",tfm)\n",
    "valid_data = MyDataset(\"./Font_npy_90_val\",tfm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258d3dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time, tqdm\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "\n",
    "model = MyNet(Block, [1,1],52)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.25)\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = valid(model,valid_loader, criterion)\n",
    "\n",
    "    print(\"Epoch[{}/{}], Train Loss:{:.4f}, Train Acc:{:.2f}, Valid Loss:{:.4f}, Valid Acc:{:.2f}\".format(epoch+1, num_epochs, train_loss, train_acc, valid_loss, valid_acc))\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9cda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcabd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=128,\n",
    "                                           )\n",
    "\n",
    "\n",
    "model = MyNet(_,_,52)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d83dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "45.24637711048126 tensor(0.7123, device='cuda:0') 58.95290967822075 tensor(0.8004, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "13.31800439953804 tensor(0.9133, device='cuda:0') 22.97098308801651 tensor(0.9060, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "8.013523355126381 tensor(0.9460, device='cuda:0') 18.601570542901754 tensor(0.9187, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "5.2809059247374535 tensor(0.9626, device='cuda:0') 16.429806185886264 tensor(0.9277, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "3.9289811849594116 tensor(0.9731, device='cuda:0') 15.395060632377863 tensor(0.9337, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.9624998569488525 tensor(0.9800, device='cuda:0') 16.003679420799017 tensor(0.9328, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.803067624568939 tensor(0.9804, device='cuda:0') 15.127574482001364 tensor(0.9372, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.3653817251324654 tensor(0.9830, device='cuda:0') 15.826501282863319 tensor(0.9374, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.1271196864545345 tensor(0.9844, device='cuda:0') 15.779200823511928 tensor(0.9363, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.911558659747243 tensor(0.9868, device='cuda:0') 17.256100508384407 tensor(0.9329, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.031828135251999 tensor(0.9854, device='cuda:0') 15.283095813822001 tensor(0.9392, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "2.045758556574583 tensor(0.9860, device='cuda:0') 17.11366183264181 tensor(0.9364, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.9366309456527233 tensor(0.9864, device='cuda:0') 17.198922836221755 tensor(0.9386, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.8572444207966328 tensor(0.9864, device='cuda:0') 18.548473802395165 tensor(0.9337, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.6884345076978207 tensor(0.9877, device='cuda:0') 17.90728289494291 tensor(0.9367, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.724695235490799 tensor(0.9874, device='cuda:0') 17.04761801660061 tensor(0.9371, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.6122588980942965 tensor(0.9885, device='cuda:0') 17.216065711108968 tensor(0.9404, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.7220695354044437 tensor(0.9884, device='cuda:0') 18.14622380398214 tensor(0.9347, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.816275954246521 tensor(0.9871, device='cuda:0') 18.175127782858908 tensor(0.9329, device='cuda:0')\n",
      "torch.Size([1024, 1, 90, 90])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 52])\n",
      "1.7230438310652971 tensor(0.9878, device='cuda:0') 17.348888791166246 tensor(0.9391, device='cuda:0')\n",
      "451.2704391479492\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = valid(model,valid_loader, criterion)\n",
    "    print(train_loss,train_acc,valid_loss,valid_acc)\n",
    "    trl.append(train_loss)\n",
    "    tra.append(train_acc)\n",
    "    vall.append(valid_loss)\n",
    "    vala.append(valid_acc)\n",
    "end = time.time()  \n",
    "torch.save(model.state_dict(), \"./20140269.pth\")\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e10a52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./mymodel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639da8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(vall,label='val')\n",
    "plt.plot(trl,label='train')\n",
    "plt.legend()\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04801dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.400879357956,\n",
       " 13.581956744688796,\n",
       " 12.546932196477428,\n",
       " 14.548767038213555,\n",
       " 11.975597213197034,\n",
       " 12.002720617703744,\n",
       " 10.600452343554934,\n",
       " 9.413485810364364,\n",
       " 11.728474826726597,\n",
       " 10.704889101718436]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efe6929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27d52ddff10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vala,label='val')\n",
    "plt.plot(tra,label='train')\n",
    "plt.title('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89c9f2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9857, device='cuda:0'),\n",
       " tensor(0.9864, device='cuda:0'),\n",
       " tensor(0.9861, device='cuda:0'),\n",
       " tensor(0.9856, device='cuda:0'),\n",
       " tensor(0.9869, device='cuda:0'),\n",
       " tensor(0.9871, device='cuda:0'),\n",
       " tensor(0.9874, device='cuda:0'),\n",
       " tensor(0.9884, device='cuda:0'),\n",
       " tensor(0.9880, device='cuda:0'),\n",
       " tensor(0.9887, device='cuda:0')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "230d6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9897, device='cuda:0'),\n",
       " tensor(0.9870, device='cuda:0'),\n",
       " tensor(0.9893, device='cuda:0'),\n",
       " tensor(0.9868, device='cuda:0'),\n",
       " tensor(0.9886, device='cuda:0'),\n",
       " tensor(0.9895, device='cuda:0'),\n",
       " tensor(0.9894, device='cuda:0'),\n",
       " tensor(0.9912, device='cuda:0'),\n",
       " tensor(0.9898, device='cuda:0'),\n",
       " tensor(0.9901, device='cuda:0')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6bf2ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(18432, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, npy_dir,tfms=None):\n",
    "        self.dir_path = npy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        # all npy path\n",
    "        self.npy_path = glob.glob(os.path.join(npy_dir, '*','*.npy')) \n",
    "        self.tfms = tfms\n",
    "    def __getitem__(self, index):\n",
    "        # load data\n",
    "        single_data_path = self.npy_path[index]\n",
    "        data = np.load(single_data_path, allow_pickle=True)\n",
    "        \n",
    "        image = data[0]\n",
    "        if self.tfms:\n",
    "            image = self.tfms(image)\n",
    "        else:\n",
    "            image = self.to_tensor(image)\n",
    "        label = data[1]\n",
    "       \n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        out = model(image)\n",
    "        if i ==0:\n",
    "            print(image.shape)\n",
    "            print(label.shape)\n",
    "            print(out.shape)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        acc += (pred==label).sum()\n",
    "        epoch_loss += loss.item()\n",
    "        total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "\n",
    "def valid(model, data_loader, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = model(image)\n",
    "            loss = criterion(out, label)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            acc += (pred==label).sum()\n",
    "            epoch_loss += loss.item()\n",
    "            total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "tfm = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5), (0.497))])\n",
    "# load dataset \n",
    "train_data = MyDataset(\"./Font_npy_90_train\",tfm)\n",
    "# valid_data = MyDataset(\"./Font_npy_90_train\",tfm)\n",
    "\n",
    "#####\n",
    "\n",
    "# define dataloader\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,                                 \n",
    "                                           num_workers=2,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "#                                            batch_size=128,\n",
    "#                                            num_workers=2,\n",
    "#                                            )\n",
    "\n",
    "model = MyNet(_,_,52)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "################\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "trl = []\n",
    "tra = []\n",
    "vall =[]\n",
    "vala = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "#     valid_loss, valid_acc = valid(model,valid_loader, criterion)\n",
    "#     print(train_loss,train_acc,valid_loss,valid_acc)\n",
    "#     trl.append(train_loss)\n",
    "#     tra.append(train_acc)\n",
    "#     vall.append(valid_loss)\n",
    "#     vala.append(valid_acc)\n",
    "    # if valid_loss < best_valid_loss:\n",
    "    #     best_valid_loss = valid_loss\n",
    "    #     best_epoch = epoch\n",
    "    #     torch.save(model.state_dict(), \"./epoch_{}.pth\".format(epoch))\n",
    "end = time.time()  \n",
    "torch.save(model.state_dict(), \"./20140269.pth\")\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6306a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9397, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%writefile test.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(18432, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, npy_dir,tfms=None):\n",
    "        self.dir_path = npy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        # all npy path\n",
    "        self.npy_path = glob.glob(os.path.join(npy_dir, '*','*.npy')) \n",
    "        self.tfms = tfms\n",
    "    def __getitem__(self, index):\n",
    "        # load data\n",
    "        single_data_path = self.npy_path[index]\n",
    "        data = np.load(single_data_path, allow_pickle=True)\n",
    "        \n",
    "        image = data[0]\n",
    "        if self.tfms:\n",
    "            image = self.tfms(image)\n",
    "        else:\n",
    "            image = self.to_tensor(image)\n",
    "        label = data[1]\n",
    "       \n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "\n",
    "def valid(model, data_loader, criterion):\n",
    "    epoch_loss, acc = 0, 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            out = model(image)\n",
    "            loss = criterion(out, label)\n",
    "            _, pred = torch.max(out.data, 1)\n",
    "            acc += (pred==label).sum()\n",
    "            epoch_loss += loss.item()\n",
    "            total += float(len(image))\n",
    "\n",
    "    return epoch_loss, acc /total\n",
    "tfm = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5), (0.497))])\n",
    "\n",
    "valid_data = MyDataset(\"./Font_npy_90_val\",tfm)\n",
    "\n",
    "#####\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                           batch_size=128,\n",
    "                                           )\n",
    "\n",
    "model = MyNet(_,_,52)\n",
    "model.load_state_dict(torch.load('./20140269.pth'))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "valid_loss, valid_acc = valid(model,valid_loader, criterion)\n",
    "valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9591afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20140269.pth.pth\n",
      "4李④낵�젣.docx\n",
      "Font_npy_90_train\n",
      "Font_npy_90_train.zip\n",
      "Font_npy_90_val\n",
      "Font_npy_90_val.zip\n",
      "last_怨쇱젣.ipynb\n",
      "model.pth\n",
      "test.py\n",
      "train.py\n",
      "~$4李④낵�젣.docx\n",
      "~WRL0532.tmp\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride):\n",
    "        super(Block, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self.conv1 =  nn.Conv2d(inplanes, planes, kernel_size=3,stride=stride,bias=False,padding=1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(16, 32, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[9/10], Train Loss:7.9414, Train Acc:0.95\n",
    "# 2.328733094036579 tensor(0.9246, device='cuda:0')\n",
    "# torch.Size([1024, 1, 90, 90])\n",
    "# torch.Size([1024])\n",
    "# torch.Size([1024, 52])\n",
    "# 100%|██████████| 10/10 [04:35<00:00, 27.57s/it]\n",
    "# Epoch[10/10], Train Loss:7.3846, Train Acc:0.95\n",
    "# 2.2121686339378357 tensor(0.9281, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c39feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride):\n",
    "        super(Block, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        self.conv1 =  nn.Conv2d(inplanes, planes, kernel_size=3,stride=stride,bias=False,padding=1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                norm_layer(planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nnDropout(0.5),\n",
    "        self.fc = nn.Linear(9216, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[23/40], Train Loss:1.6554, Train Acc:0.99\n",
    "# 1.780292920768261 tensor(0.9538, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6edc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "                \n",
    "#         self.dropout = nnDropout(0.3),\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.shape)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[31/40], Train Loss:1.5932, Train Acc:0.99\n",
    "# 1.2462433874607086 tensor(0.9590, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.downsample3 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "            )\n",
    "                \n",
    "#         self.dropout = nnDropout(0.3),\n",
    "        self.fc = nn.Linear(2304, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        ident = self.downsample3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x) + ident\n",
    "        x = self.relu4(x)        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.shape)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[28/40], Train Loss:1.7391, Train Acc:0.98\n",
    "# 1.2742572948336601 tensor(0.9582, device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df229f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[40/40], Train Loss:2.6018, Train Acc:0.98\n",
    "# 1.3340800106525421 tensor(0.9581, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classe):\n",
    "        super(MyNet, self).__init__()\n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        self.dilation = 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "            )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(4608, num_classe)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        ident = self.downsample1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) + ident\n",
    "        x = self.relu2(x)\n",
    "        ident = self.downsample2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x) + ident\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "# Epoch[39/40], Train Loss:1.8657, Train Acc:0.98\n",
    "# 1.3427405655384064 tensor(0.9606, device='cuda:0')\n",
    "# torch.Size([1024, 1, 90, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e28de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam weight decay\n",
    "\n",
    "\n",
    "# Epoch[27/50], Train Loss:1.9248, Train Acc:0.98\n",
    "# 1.3467636704444885 tensor(0.9604, device='cuda:0')\n",
    "# torch.Size([1024, 1, 90, 90])\n",
    "# torch.Size([1024])\n",
    "# torch.Size([1024, 52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "모델 with 0.001\n",
    "Epoch[5/5], Train Loss:8.7186, Train Acc:0.94\n",
    "2.086592584848404 tensor(0.9347, device='cuda:0')\n",
    "\n",
    "모델 with 0.0005\n",
    "\n",
    "Train Acc:0.92\n",
    "valid acc : 0.92\n",
    "\n",
    "model with 0.005\n",
    "Epoch[5/20], Train Loss:9.8456, Train Acc:0.93\n",
    "2.388212338089943 tensor(0.9238, device='cuda:0')\n",
    "\n",
    "\n",
    "model with 0.002\n",
    "Epoch[5/20], Train Loss:8.0757, Train Acc:0.94\n",
    "2.0057855620980263 tensor(0.9368, device='cuda:0')\n",
    "\n",
    "model with 0.003\n",
    "Epoch[5/20], Train Loss:8.6232, Train Acc:0.94\n",
    "2.1346734762191772 tensor(0.9329, device='cuda:0')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "경량화 -> resnet 1,1 : 27->42초로 늘어남 epoch당\n",
    "10분에 94까지밖에 못감\n",
    "'''\n",
    "\n",
    "'''\n",
    "16부터 lr 조절?\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
